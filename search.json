[{"path":"/articles/introduction.html","id":"notes","dir":"Articles","previous_headings":"","what":"Notes","title":"Introduction","text":"variables package considered categorical (discrete) variables Later see spartropy functions available log() (natural logarithm), log2() log10() Note \\(0 \\log 0 = 0\\) convention corresponds also limit","code":""},{"path":[]},{"path":"/articles/introduction.html","id":"entropy-mathrmh","dir":"Articles","previous_headings":"Definitions and formulas","what":"Entropy, \\(\\mathrm{H}\\)","title":"Introduction","text":"Definition: \\[\\begin{align}   \\mathrm{H}(X) &= - \\sum_{x} P(X = x) \\log P(X = x) \\end{align}\\] sum possible values \\(X\\), denoted \\(x\\). Source: https://en.wikipedia.org/wiki/Entropy_(information_theory)","code":""},{"path":"/articles/introduction.html","id":"joint-entropy-mathrmhx-y-symmetric-in-x-and-y","dir":"Articles","previous_headings":"Definitions and formulas","what":"Joint entropy, \\(\\mathrm{H}(X, Y)\\) (symmetric in \\(X\\) and \\(Y\\))","title":"Introduction","text":"Definition: \\[\\begin{align}   \\mathrm{H}(X , Y)    &= - \\sum_{x, y} P(X = x , Y = y) \\log P(X = x , Y = y)  \\end{align}\\] sum possible values \\(X\\), denoted \\(x\\), possible values \\(Y\\), denoted \\(y\\). Source: https://en.wikipedia.org/wiki/Joint_entropy","code":""},{"path":"/articles/introduction.html","id":"conditional-entropy-mathrmhx-mid-y-asymmetric-in-x-and-y","dir":"Articles","previous_headings":"Definitions and formulas","what":"Conditional entropy, \\(\\mathrm{H}(X \\mid Y)\\) (asymmetric in \\(X\\) and \\(Y\\))","title":"Introduction","text":"Definition: \\[\\begin{align}   \\mathrm{H}(X \\mid Y)    &= - \\sum_{x, y} P(X = x , Y = y) \\log \\frac{P(X = x , Y = y)}{P(Y = y)}  \\end{align}\\] Formulas: \\[\\begin{align}   \\mathrm{H}(X \\mid Y) &= \\mathrm{H}(X, Y) - \\mathrm{H}(Y) \\\\   \\mathrm{H}(Y \\mid X) &= \\mathrm{H}(X, Y) - \\mathrm{H}(X)  \\end{align}\\] \\[\\begin{align}   \\mathrm{H}(X , Y)    &= \\mathrm{H}(X \\mid Y) + \\mathrm{H}(Y) \\\\   &= \\mathrm{H}(Y \\mid X) + \\mathrm{H}(X)  \\end{align}\\] Source: https://en.wikipedia.org/wiki/Conditional_entropy","code":""},{"path":"/articles/introduction.html","id":"mutual-information-operatornamei-x-y-symmetric-in-x-and-y","dir":"Articles","previous_headings":"Definitions and formulas","what":"Mutual information, \\(\\operatorname{I} (X; Y)\\) (symmetric in \\(X\\) and \\(Y\\))","title":"Introduction","text":"Definition: \\[\\begin{align}   \\operatorname{} (X; Y)   &= \\sum_{x, y} P(X = x , Y = y) \\log \\frac{P(X = x , Y = y)}{P(X = x) P(Y = y)}  \\end{align}\\] Formulas: \\[\\begin{align}   \\operatorname{} (X; Y)   &= \\mathrm{H}(X) - \\mathrm{H}(X \\mid Y)\\\\    &= \\mathrm{H}(Y) - \\mathrm{H}(Y \\mid X)\\\\   &= \\mathrm{H}(X) + \\mathrm{H}(Y) - \\mathrm{H}(X,Y) \\\\   &= \\mathrm{H}(X,Y) - \\mathrm{H}(X \\mid Y) - \\mathrm{H}(Y \\mid X) \\\\   \\mathrm{H}(X \\mid Y) &= \\mathrm{H}(X) - \\operatorname{} (X; Y)  \\end{align}\\] Source: https://en.wikipedia.org/wiki/Mutual_information","code":""},{"path":"/articles/introduction.html","id":"normalised-shared-information-distance-dx-y-symmetric-in-x-and-y","dir":"Articles","previous_headings":"Definitions and formulas","what":"(Normalised) shared information distance, \\(D(X, Y)\\) (symmetric in \\(X\\) and \\(Y\\))","title":"Introduction","text":"\\[\\begin{align}   \\operatorname{D} (X, Y)   &= \\frac{ \\mathrm{H}(X \\mid Y) + \\mathrm{H}(Y \\mid X) }{\\mathrm{H}(X,Y)}  \\end{align}\\] \\(0 \\leq \\operatorname{D} (X, Y) \\leq 1\\) \\(\\operatorname{D} (X, Y) = 0\\) iff \\(X\\) \\(Y\\) perfectly dependent (fully determined) \\(\\operatorname{D} (X, Y) = 1\\) iff \\(X\\) \\(Y\\) independent. measure also sometimes called normalised independent information.","code":""},{"path":"/articles/introduction.html","id":"independence","dir":"Articles","previous_headings":"Definitions and formulas","what":"Independence","title":"Introduction","text":"\\(X\\) \\(Y\\) independent: \\[\\begin{align}   \\mathrm{H} (Y \\mid X) &= \\mathrm {H}(Y) \\\\   \\mathrm{H} (X \\mid Y) &= \\mathrm {H}(X) . \\end{align}\\]","code":""},{"path":"/articles/introduction.html","id":"functions","dir":"Articles","previous_headings":"","what":"Functions","title":"Introduction","text":"entropyB(d) calculates entropy \\(H(X)\\) joint entropy \\(H(\\ldots)\\) entropy_condB(d, idx_x, idx_y) calculates conditional entropy \\(H(X \\mid Y)\\) d[, idx_x] given d[, idx_y] mutinfB(d, idx_x, idx_y) calculates mutual information d[, idx_x] d[, idx_y] B either E natural logarithm 2 \\(\\log2\\) 10 \\(\\log10\\)","code":""},{"path":"/articles/introduction.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"Introduction","text":"Using mtcars data:","code":"head(mtcars) #>                    mpg cyl disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 #> Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 #> Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 #> Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 #> Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1"},{"path":"/articles/introduction.html","id":"htextmpg","dir":"Articles","previous_headings":"Example","what":"\\(H(\\text{mpg})\\)","title":"Introduction","text":"Entropy, \\(H\\) mpt variable, .e. \\(H(\\text{mpg})\\):","code":"H_mpg <- entropyE(mtcars[, \"mpg\"]) H_mpg #> [1] 3.162484"},{"path":"/articles/introduction.html","id":"htextmpg-texthp-textwt","dir":"Articles","previous_headings":"Example","what":"\\(H(\\text{mpg}, \\text{hp}, \\text{wt})\\)","title":"Introduction","text":"","code":"H_joint <- entropyE(mtcars[, c(\"mpg\", \"hp\", \"wt\")]) H_joint #> [1] 3.465736"},{"path":"/articles/introduction.html","id":"itextmpg-texthp-textwt","dir":"Articles","previous_headings":"Example","what":"\\(I(\\text{mpg}; \\text{hp}, \\text{wt})\\)","title":"Introduction","text":"","code":"idx_x <- match(\"mpg\", colnames(mtcars)) idx_y <- match(c(\"hp\", \"wt\"), colnames(mtcars)) I_mpg_hpwt <- mutinfE(mtcars, idx_x, idx_y) I_mpg_hpwt #> [1] 3.119162"},{"path":"/articles/introduction.html","id":"htextmpg-mid-texthp-textwt","dir":"Articles","previous_headings":"Example","what":"\\(H(\\text{mpg} \\mid \\text{hp}, \\text{wt})\\)","title":"Introduction","text":"\\[\\begin{align}   \\mathrm{H}(X \\mid Y) &= \\mathrm{H}(X) - \\operatorname{} (X; Y) \\\\   \\mathrm{H}(\\text{mpg} \\mid \\text{hp}, \\text{wt})    &= \\mathrm{H}(\\text{mpg}) - \\operatorname{} (\\text{mpg}; \\text{hp}, \\text{wt}) \\\\ \\end{align}\\] \\[\\begin{align}   \\mathrm{H}(\\text{hp}, \\text{wt} \\mid \\text{mpg})    &= \\mathrm{H}(\\text{hp}, \\text{wt}) - \\operatorname{} (\\text{mpg}; \\text{hp}, \\text{wt}) \\\\ \\end{align}\\] \\[\\begin{align}   \\operatorname{D} (\\text{mpg}, \\{ \\text{hp}, \\text{wt} \\})   &= \\frac{ \\mathrm{H}(\\text{mpg} \\mid \\text{hp}, \\text{wt}) +      \\mathrm{H}(\\text{hp}, \\text{wt} \\mid \\text{mpg}) }{\\mathrm{H}(\\text{mpg}, \\text{hp}, \\text{wt})}  \\end{align}\\] Thus, \\(D\\) close 0, hp wt says alot mpg (vica versa).","code":"H_mpg_hpwt <- H_mpg - I_mpg_hpwt H_mpg_hpwt #> [1] 0.0433217 entropy_condE(mtcars, idx_x, idx_y) #> [1] 0.0433217 H_hpwt <- entropyE(mtcars[, c(\"hp\", \"wt\")]) H_hpwt_mpg <- H_hpwt - I_mpg_hpwt H_hpwt_mpg #> [1] 0.3032519 entropy_condE(mtcars, idx_y, idx_x) #> [1] 0.3032519 D_mpg_hpwt <- (H_mpg_hpwt + H_hpwt_mpg) / H_joint D_mpg_hpwt #> [1] 0.1 (entropy_condE(mtcars, idx_x, idx_y) + entropy_condE(mtcars, idx_y, idx_x)) / entropyE(mtcars[, c(\"mpg\", \"hp\", \"wt\")]) #> [1] 0.1"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Mikkel Meyer Andersen. Author, maintainer, copyright holder.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Andersen M (2022). spartropy: Sparse Entropy High Dimensions Observed Categorical Data. R package version 1.0.","code":"@Manual{,   title = {spartropy: Sparse Entropy in High Dimensions from Observed Categorical Data},   author = {Mikkel Meyer Andersen},   year = {2022},   note = {R package version 1.0}, }"},{"path":"/index.html","id":"spartropy","dir":"","previous_headings":"","what":"Sparse Entropy in High Dimensions from Observed Categorical Data","title":"Sparse Entropy in High Dimensions from Observed Categorical Data","text":"Sparse entropy (high dimension)","code":""},{"path":"/reference/df2intmat.html","id":null,"dir":"Reference","previous_headings":"","what":"Converts data frame to integer matrix — df2intmat","title":"Converts data frame to integer matrix — df2intmat","text":"conversion done converting characters, factor integer","code":""},{"path":"/reference/df2intmat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converts data frame to integer matrix — df2intmat","text":"","code":"df2intmat(x)"},{"path":"/reference/df2intmat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Converts data frame to integer matrix — df2intmat","text":"x Data frame","code":""},{"path":"/reference/df2intmat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Converts data frame to integer matrix — df2intmat","text":"","code":"x <- mtcars[1:4, 1:5] x #>                 mpg cyl disp  hp drat #> Mazda RX4      21.0   6  160 110 3.90 #> Mazda RX4 Wag  21.0   6  160 110 3.90 #> Datsun 710     22.8   4  108  93 3.85 #> Hornet 4 Drive 21.4   6  258 110 3.08 df2intmat(x) #> Error in df2intmat(x): could not find function \"df2intmat\""},{"path":"/reference/entropy10.html","id":null,"dir":"Reference","previous_headings":"","what":"Entropy using `log10()` — entropy10","title":"Entropy using `log10()` — entropy10","text":"Se Introduction vignette definition.","code":""},{"path":"/reference/entropy10.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Entropy using `log10()` — entropy10","text":"","code":"entropy10(d)"},{"path":"/reference/entropy10.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Entropy using `log10()` — entropy10","text":"d Vector matrix observations","code":""},{"path":"/reference/entropy2.html","id":null,"dir":"Reference","previous_headings":"","what":"Entropy using `log2()` — entropy2","title":"Entropy using `log2()` — entropy2","text":"Se Introduction vignette definition.","code":""},{"path":"/reference/entropy2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Entropy using `log2()` — entropy2","text":"","code":"entropy2(d)"},{"path":"/reference/entropy2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Entropy using `log2()` — entropy2","text":"d Vector matrix observations","code":""},{"path":"/reference/entropyE.html","id":null,"dir":"Reference","previous_headings":"","what":"Entropy using `log()` (natural logarithm) — entropyE","title":"Entropy using `log()` (natural logarithm) — entropyE","text":"Se Introduction vignette definition.","code":""},{"path":"/reference/entropyE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Entropy using `log()` (natural logarithm) — entropyE","text":"","code":"entropyE(d)"},{"path":"/reference/entropyE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Entropy using `log()` (natural logarithm) — entropyE","text":"d Vector matrix observations","code":""},{"path":"/reference/entropy_cond10.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional entropy of $X$ given $Y$ using `log10()` — entropy_cond10","title":"Conditional entropy of $X$ given $Y$ using `log10()` — entropy_cond10","text":"Conditional entropy $X$ given $Y$ using `log10()`","code":""},{"path":"/reference/entropy_cond10.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional entropy of $X$ given $Y$ using `log10()` — entropy_cond10","text":"","code":"entropy_cond10(d, idx_x, idx_y)"},{"path":"/reference/entropy_cond10.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional entropy of $X$ given $Y$ using `log10()` — entropy_cond10","text":"d Integer matrix data row single observation idx_x Indicies (integer vector) variable set $X$ (1 `ncol(d)`) idx_y Indicies (integer vector) variable set $Y$ (1 `ncol(d)`)","code":""},{"path":"/reference/entropy_cond2.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional entropy of $X$ given $Y$ using `log2()` — entropy_cond2","title":"Conditional entropy of $X$ given $Y$ using `log2()` — entropy_cond2","text":"Conditional entropy $X$ given $Y$ using `log2()`","code":""},{"path":"/reference/entropy_cond2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional entropy of $X$ given $Y$ using `log2()` — entropy_cond2","text":"","code":"entropy_cond2(d, idx_x, idx_y)"},{"path":"/reference/entropy_cond2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional entropy of $X$ given $Y$ using `log2()` — entropy_cond2","text":"d Integer matrix data row single observation idx_x Indicies (integer vector) variable set $X$ (1 `ncol(d)`) idx_y Indicies (integer vector) variable set $Y$ (1 `ncol(d)`)","code":""},{"path":"/reference/entropy_condE.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional entropy of $X$ given $Y$ using `log()` (natural logarithm) — entropy_condE","title":"Conditional entropy of $X$ given $Y$ using `log()` (natural logarithm) — entropy_condE","text":"Conditional entropy $X$ given $Y$ using `log()` (natural logarithm)","code":""},{"path":"/reference/entropy_condE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional entropy of $X$ given $Y$ using `log()` (natural logarithm) — entropy_condE","text":"","code":"entropy_condE(d, idx_x, idx_y)"},{"path":"/reference/entropy_condE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional entropy of $X$ given $Y$ using `log()` (natural logarithm) — entropy_condE","text":"d Integer matrix data row single observation idx_x Indicies (integer vector) variable set $X$ (1 `ncol(d)`) idx_y Indicies (integer vector) variable set $Y$ (1 `ncol(d)`)","code":""},{"path":"/reference/infdist10.html","id":null,"dir":"Reference","previous_headings":"","what":"Shared information distance of $X$ and $Y$ using `log10()` — infdist10","title":"Shared information distance of $X$ and $Y$ using `log10()` — infdist10","text":"Shared information distance $X$ $Y$ using `log10()`","code":""},{"path":"/reference/infdist10.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shared information distance of $X$ and $Y$ using `log10()` — infdist10","text":"","code":"infdist10(d, idx_x, idx_y)"},{"path":"/reference/infdist10.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shared information distance of $X$ and $Y$ using `log10()` — infdist10","text":"d Integer matrix data row single observation idx_x Indicies (integer vector) variable set $X$ (1 `ncol(d)`) idx_y Indicies (integer vector) variable set $Y$ (1 `ncol(d)`)","code":""},{"path":"/reference/infdist2.html","id":null,"dir":"Reference","previous_headings":"","what":"Shared information distance of $X$ and $Y$ using `log2()` — infdist2","title":"Shared information distance of $X$ and $Y$ using `log2()` — infdist2","text":"Shared information distance $X$ $Y$ using `log2()`","code":""},{"path":"/reference/infdist2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shared information distance of $X$ and $Y$ using `log2()` — infdist2","text":"","code":"infdist2(d, idx_x, idx_y)"},{"path":"/reference/infdist2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shared information distance of $X$ and $Y$ using `log2()` — infdist2","text":"d Integer matrix data row single observation idx_x Indicies (integer vector) variable set $X$ (1 `ncol(d)`) idx_y Indicies (integer vector) variable set $Y$ (1 `ncol(d)`)","code":""},{"path":"/reference/infdistE.html","id":null,"dir":"Reference","previous_headings":"","what":"Shared information distance of $X$ and $Y$ using `log()` (natural logarithm) — infdistE","title":"Shared information distance of $X$ and $Y$ using `log()` (natural logarithm) — infdistE","text":"Shared information distance $X$ $Y$ using `log()` (natural logarithm)","code":""},{"path":"/reference/infdistE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shared information distance of $X$ and $Y$ using `log()` (natural logarithm) — infdistE","text":"","code":"infdistE(d, idx_x, idx_y)"},{"path":"/reference/infdistE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shared information distance of $X$ and $Y$ using `log()` (natural logarithm) — infdistE","text":"d Integer matrix data row single observation idx_x Indicies (integer vector) variable set $X$ (1 `ncol(d)`) idx_y Indicies (integer vector) variable set $Y$ (1 `ncol(d)`)","code":""},{"path":"/reference/mutinf10.html","id":null,"dir":"Reference","previous_headings":"","what":"Mutual information using `log10()` — mutinf10","title":"Mutual information using `log10()` — mutinf10","text":"Mutual information using `log10()`","code":""},{"path":"/reference/mutinf10.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mutual information using `log10()` — mutinf10","text":"","code":"mutinf10(d, idx_x, idx_y)"},{"path":"/reference/mutinf10.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mutual information using `log10()` — mutinf10","text":"d Integer matrix data row single observation idx_x Indicies (integer vector) variable set $X$ (1 `ncol(d)`) idx_y Indicies (integer vector) variable set $Y$ (1 `ncol(d)`)","code":""},{"path":"/reference/mutinf2.html","id":null,"dir":"Reference","previous_headings":"","what":"Mutual information using `log2()` — mutinf2","title":"Mutual information using `log2()` — mutinf2","text":"Mutual information using `log2()`","code":""},{"path":"/reference/mutinf2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mutual information using `log2()` — mutinf2","text":"","code":"mutinf2(d, idx_x, idx_y)"},{"path":"/reference/mutinf2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mutual information using `log2()` — mutinf2","text":"d Integer matrix data row single observation idx_x Indicies (integer vector) variable set $X$ (1 `ncol(d)`) idx_y Indicies (integer vector) variable set $Y$ (1 `ncol(d)`)","code":""},{"path":"/reference/mutinfE.html","id":null,"dir":"Reference","previous_headings":"","what":"Mutual information using `log()` (natural logarithm) — mutinfE","title":"Mutual information using `log()` (natural logarithm) — mutinfE","text":"Mutual information using `log()` (natural logarithm)","code":""},{"path":"/reference/mutinfE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mutual information using `log()` (natural logarithm) — mutinfE","text":"","code":"mutinfE(d, idx_x, idx_y)"},{"path":"/reference/mutinfE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mutual information using `log()` (natural logarithm) — mutinfE","text":"d Integer matrix data row single observation idx_x Indicies (integer vector) variable set $X$ (1 `ncol(d)`) idx_y Indicies (integer vector) variable set $Y$ (1 `ncol(d)`)","code":""},{"path":"/reference/spartropy-package.html","id":null,"dir":"Reference","previous_headings":"","what":"A short title line describing what the package does — spartropy-package","title":"A short title line describing what the package does — spartropy-package","text":"detailed description package . length   one five lines recommended.","code":""},{"path":"/reference/spartropy-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A short title line describing what the package does — spartropy-package","text":"section provide detailed overview use   package, including important functions.","code":""},{"path":"/reference/spartropy-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"A short title line describing what the package does — spartropy-package","text":"Name, email optional. Maintainer: Name <@email.com>","code":""},{"path":"/reference/spartropy-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A short title line describing what the package does — spartropy-package","text":"optional section can contain literature references   background information.","code":""},{"path":[]},{"path":"/reference/spartropy-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A short title line describing what the package does — spartropy-package","text":"","code":"if (FALSE) {      ## Optional simple examples of the most important functions      ## These can be in \\dontrun{} and \\donttest{} blocks.      }"}]
